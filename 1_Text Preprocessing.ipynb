{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0162ac4",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03a0ba64",
   "metadata": {},
   "source": [
    "This jupyter notebook serves the purpose of performing text preprocessing and language detection on a corpus of sentences. The aim of the code is to prepare the text data for further analysis or modeling by applying various preprocessing steps and filtering out non-English sentences. Specifically, the code aims to achieve the following:\n",
    "\n",
    "- **Data Cleaning**: The code checks the number of duplicated or null datapoints and remove them if needed.\n",
    "\n",
    "- **Language Detection**: The code detects the language of each sentence in the given corpus and retains only the English sentences for further processing. This step ensures that subsequent analysis or modeling is focused on English text data.\n",
    "\n",
    "- **Text Preprocessing**: The code applies a series of text preprocessing steps to each English sentence. This includes converting the text to lowercase, removing punctuation, tokenizing the text into individual words, removing stop words, expanding contractions, and lemmatizing the words. These preprocessing steps help clean and normalize the text data, making it more suitable for downstream tasks such as sentiment analysis, topic modeling, or information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652848af",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be3bc772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f261a40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42656 entries, 0 to 42655\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Review_ID          42656 non-null  int64 \n",
      " 1   Rating             42656 non-null  int64 \n",
      " 2   Year_Month         42656 non-null  object\n",
      " 3   Reviewer_Location  42656 non-null  object\n",
      " 4   Review_Text        42656 non-null  object\n",
      " 5   Branch             42656 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "disney = pd.read_csv(\"DisneylandReviews.csv\", encoding='latin-1')\n",
    "\n",
    "disney.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f914aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This analysis only deals with the text column\n",
    "df = disney[\"Review_Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e35bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'If you've ever been to Disneyland anywhere you'll find Disneyland Hong Kong very similar in the layout when you walk into main street! It has a very familiar feel. One of the rides  its a Small World  is absolutely fabulous and worth doing. The day we visited was fairly hot and relatively busy but the queues moved fairly well. '\n",
      "'Its been a while since d last time we visit HK Disneyland .. Yet, this time we only stay in Tomorrowland .. AKA Marvel land!Now they have Iron Man Experience n d Newly open Ant Man n d Wasp!!Ironman .. Great feature n so Exciting, especially d whole scenery of HK (HK central area to Kowloon)!Antman .. Changed by previous Buzz lightyear! More or less d same, but I'm expecting to have something most!!However, my boys like it!!Space Mountain .. Turns into Star Wars!! This 1 is Great!!!For cast members (staffs) .. Felt bit MINUS point from before!!! Just dun feel like its a Disney brand!! Seems more local like Ocean Park or even worst!!They got no SMILING face, but just wanna u to enter n attraction n leave!!Hello this is supposed to be Happiest Place on Earth brand!! But, just really Dont feel it!!Bakery in Main Street now have more attractive delicacies n Disney theme sweets .. These are Good Points!!Last, they also have Starbucks now inside the theme park!!'\n",
      "'Thanks God it wasn   t too hot or too humid when I was visiting the park   otherwise it would be a big issue (there is not a lot of shade).I have arrived around 10:30am and left at 6pm. Unfortunately I didn   t last until evening parade, but 8.5 hours was too much for me.There is plenty to do and everyone will find something interesting for themselves to enjoy.It wasn   t extremely busy and the longest time I had to queue for certain attractions was 45 minutes (which is really not that bad).Although I had an amazing time, I felt a bit underwhelmed with choice of rides and attractions. The park itself is quite small (I was really expecting something grand   even the main castle which was closed by the way was quite small).The food options are good, few coffee shops (including Starbucks) and plenty of gift shops. There was no issue with toilets as they are everywhere.All together it was a great day out and I really enjoyed it.'\n"
     ]
    }
   ],
   "source": [
    "# Extract the first three sentences from the 'Review_Text' column for the comparison with the text after the preprocessing in the end\n",
    "raw_sentences = disney['Review_Text'][:3]\n",
    "\n",
    "# Convert each sentence to the desired format\n",
    "formatted_raw_sentences = [\"'\" + sentence + \"'\" for sentence in raw_sentences]\n",
    "\n",
    "# Print the formatted raw sentences\n",
    "for sentence in formatted_raw_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b6850b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the duplicated rows\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa510b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the null rows\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615cbff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd862daf",
   "metadata": {},
   "source": [
    "## Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66692b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/ijeonghyeon/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ijeonghyeon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ijeonghyeon/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ijeonghyeon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from langdetect import detect\n",
    "import string\n",
    "import re\n",
    "import contractions\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d7aff",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb1209a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting the language and extract only english sentences\n",
    "corpus = []\n",
    "\n",
    "for text in df:\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        if lang == \"en\":\n",
    "            corpus.append(text)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24abe4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define general text preprocessing model\n",
    "def text_preprocessing(text):\n",
    "    # Convert to lowercase\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Tokenize the text\n",
    "    text_tokens = nltk.word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_text = [word for word in text_tokens if not word in stop_words]\n",
    "    # Join the filtered words back into a string\n",
    "    text = ' '.join(filtered_text)\n",
    "    # Replace contractions with their expanded form\n",
    "    text = contractions.fix(text)\n",
    "    return text\n",
    "\n",
    "# Define a function that takes a sentence as input and returns a list of lemmas\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_nltk(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    # Perform part-of-speech tagging on the tokens \n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    lemmas = []\n",
    "    for token, tag in pos_tags:\n",
    "        # Map the POS tag to the corresponding WordNet POS tag\n",
    "        tag = get_wordnet_pos(tag)\n",
    "        if tag:\n",
    "            lemma = lemmatizer.lemmatize(token, tag)\n",
    "        else:\n",
    "            lemma = lemmatizer.lemmatize(token)\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "# Define a function that maps NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    "    elif tag.startswith('V'):\n",
    "        return 'v'\n",
    "    elif tag.startswith('J'):\n",
    "        return 'a'\n",
    "    elif tag.startswith('R'):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00edd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text processing and lemmatizing\n",
    "processed_corpus = []\n",
    "\n",
    "for text in corpus:\n",
    "    result = text_preprocessing(text)\n",
    "    result = lemmatize_nltk(result)\n",
    "    processed_corpus.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6742db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list into the Series\n",
    "text = pd.Series(processed_corpus)\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for doc in text:\n",
    "    sent= \" \".join(doc)\n",
    "    sentences.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bea25952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you have ever disneyland anywhere you will find disneyland hong kong similar layout walk main street familiar feel one rid small world absolutely fabulous worth day visit fairly hot relatively busy queue move fairly well',\n",
       " 'since last time visit hk disneyland yet time stay tomorrowland aka marvel landnow iron man experience n newly open ant man n waspironman great feature n excite especially whole scenery hk hk central area kowloonantman change previous buzz lightyear less i be expect something mosthowever boys like itspace mountain turn star war 1 greatfor cast member staff felt bit minus point dun feel like disney brand seem local like ocean park even worstthey get smile face wan na you enter n attraction n leavehello suppose happy place earth brand really do not feel itbakery main street attractive delicacy n disney theme sweet good pointslast also starbucks inside theme park',\n",
       " 'thanks god hot humid visit park otherwise would big issue lot shadei arrive around 1030am leave 6pm unfortunately last evening parade 85 hour much methere plenty everyone find something interesting enjoyit extremely busy long time queue certain attraction 45 minute really badalthough amazing time felt bit underwhelmed choice ride attraction park quite small really expect something grand even main castle close way quite smallthe food option good coffee shop include starbucks plenty gift shop issue toilet everywhereall together great day really enjoy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print sample sentences after the text preprocessing\n",
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9a07b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42626"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of sentences after text preprocessing\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be18a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "disney_sentences = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2a2c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'disney' (DataFrame)\n",
      "Stored 'disney_sentences' (list)\n"
     ]
    }
   ],
   "source": [
    "# Store variables for further analysis\n",
    "%store disney disney_sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
