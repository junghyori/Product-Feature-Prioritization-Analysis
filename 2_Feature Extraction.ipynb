{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c9968b",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1eda1b",
   "metadata": {},
   "source": [
    "This jupyter notebook encompasses a product feature extraction process aimed at transforming raw text data into meaningful and structured features for further analysis. The process involves several key steps:\n",
    "\n",
    "## Detailed Process\n",
    "\n",
    "### 1. Filter Extreme Words:\n",
    "The code filters extreme words from the tokenized corpus, removing infrequent and highly frequent words. This step improves the quality of the data and reduces noise in subsequent analysis. It involves creating a Gensim Dictionary object from the tokenized corpus and applying filtering using the filter_extremes method.\n",
    "### 2. Topic Modeling:\n",
    "The code performs topic modeling using the Latent Dirichlet Allocation (LDA) model. It generates a bag-of-words corpus representation and builds an LDA model with a specific number of topics. The LDA model assigns topic distributions to each document in the corpus, allowing for the discovery of latent topics. \n",
    "###  3. Extract Keyword from Topics:\n",
    "The code extracts the highest probability word for each topic in the LDA model. This step identifies the most representative word for each topic, providing insights into the main theme or concept of the topic.\n",
    "###  4. POS Tagging for Only Noun:\n",
    "The code performs Part-of-Speech (POS) tagging on the highest probability words and filters out only the words identified as nouns. This helps ensure that the extracted keywords are relevant and suitable for further product feature presentation.\n",
    "### 5. Removing Unrelated Words:\n",
    "The code manually filters out unrelated keywords from the resulting DataFrame, removing words that are not meaningful or do not contribute to the topics of interest. This step improves the relevance and clarity of the extracted keywords.\n",
    "### 6. Calculate Coherence Score:\n",
    "The code calculates the coherence score using the c_v coherence measure. This measure evaluates the overall coherence of the generated topics, indicating how well the topics capture the underlying patterns in the data. A higher coherence score indicates more coherent and meaningful topics.\n",
    "\n",
    "\n",
    "By following this feature extraction process, the code enables the transformation of raw text data into structured and interpretable features, facilitating subsequent analysis, modeling, and insights generation from the given corpus of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f123fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e872e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r disney disney_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db53fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter extreme words\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "tokenized_corpus = [nltk.word_tokenize(doc) for doc in disney_sentences]\n",
    "dictionary = Dictionary(tokenized_corpus)\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b2db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "# Create a bag of words corpus\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in tokenized_corpus]\n",
    "\n",
    "# Build the LDA model with topics\n",
    "num_topics = len(disney_sentences) *0.005\n",
    "lda_model = LdaModel(corpus=bow_corpus,\n",
    "                     id2word=dictionary,\n",
    "                     num_topics=num_topics,\n",
    "                     random_state=42,\n",
    "                     update_every=1,\n",
    "                     chunksize=100,\n",
    "                     passes=10,\n",
    "                     alpha='auto',\n",
    "                     per_word_topics=True)\n",
    "\n",
    "# Iterate over each topic and print the word with the highest probability\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    words = topic.split('+')\n",
    "    highest_prob_word = words[0].split('*')[1].replace('\"', '').strip()\n",
    "    probability = float(words[0].split('*')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "887ba220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.5133559229545281\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Calculate coherence score using the c_v coherence measure for the evaluation\n",
    "coherence_model = CoherenceModel(model=lda_model, texts=tokenized_corpus, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "print(\"Coherence Score:\", coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7387277f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ijeonghyeon/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Download the required NLTK resources for POS tagging\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Create an empty DataFrame\n",
    "title_df = pd.DataFrame(columns=['Word', 'Probability'])\n",
    "\n",
    "# Iterate over each topic and populate the DataFrame\n",
    "beforetagging = []\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    words = topic.split('+')\n",
    "    highest_prob_word = words[0].split('*')[1].replace('\"', '').strip()\n",
    "    probability = float(words[0].split('*')[0])\n",
    "    beforetagging.append(highest_prob_word)\n",
    "    \n",
    "    # Perform POS tagging to identify the word category\n",
    "    pos_tags = nltk.pos_tag([highest_prob_word])\n",
    "    pos_tag = pos_tags[0][1]\n",
    "    \n",
    "    # Check if the word is a noun (singular or plural)\n",
    "    if pos_tag.startswith('NN'):\n",
    "        # Append a new row to the DataFrame\n",
    "        title_df = title_df.append({'Word': highest_prob_word, 'Probability': probability}, ignore_index=True)\n",
    "\n",
    "# Remove duplicated rows if any from the DataFrame\n",
    "title_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b71826d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of features before the POS tagging\n",
    "beforetagging = pd.DataFrame(beforetagging, columns=[\"Keyword\"])\n",
    "len(beforetagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1a9dae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of features after the POS tagging and before the manual removal\n",
    "len(title_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3e3e82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually filter unrelevant keywords from the title_df\n",
    "disney_title_df = title_df.drop(title_df[title_df[\"Word\"].isin([\"year\",\"paris\",\"child\",\"kid\",\n",
    "                                                         \"son\",\"mean\",\"daughter\",\"fun\",\n",
    "                                                        \"disney\",\"land\",\"sure\",\n",
    "                                                         \"day\",\"look\",\"weekend\",\"recommend\",\"visit\",\"place\",\n",
    "                                                         \"dream\",\"brea\",\"weather\",\"enjoy\",\"u\",\"worth\",\"thing\",\n",
    "                                                         \"bit\",\"way\",\"use\",\"decide\",\"hong\",\"start\",\"stop\",\n",
    "                                                         \"course\",\"want\",\"everything\",\"review\",\"feel\",\"beautiful\",\n",
    "                                                         \"choice\",\"family\",\"week\",\"tell\",\"need\",\"trip\",\"watch\",\n",
    "                                                         \"disneyland\",\"walt\",\"favorite\",\"experience\",\"star\",\"age\"\n",
    "                                                        ])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "66acda0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the final number of features\n",
    "len(disney_title_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "72035a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hotel</td>\n",
       "      <td>0.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lunch</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>snack</td>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>train</td>\n",
       "      <td>0.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>clean</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>buffet</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>car</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>service</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>member</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>staff</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>theme</td>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>price</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>wait</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>fast</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>queue</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>bus</td>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>parade</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>mickey</td>\n",
       "      <td>0.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>crowd</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>people</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>burger</td>\n",
       "      <td>0.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>castle</td>\n",
       "      <td>0.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>coaster</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>time</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>shop</td>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>eat</td>\n",
       "      <td>0.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>food</td>\n",
       "      <td>0.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>drink</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>room</td>\n",
       "      <td>0.353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>attraction</td>\n",
       "      <td>0.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>ticket</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>push</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>0.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>minute</td>\n",
       "      <td>0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>show</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>bar</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>pirate</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Probability\n",
       "0         hotel        0.303\n",
       "2         lunch        0.533\n",
       "14        snack        0.165\n",
       "15        train        0.316\n",
       "18        clean        0.277\n",
       "20       buffet        0.141\n",
       "26          car        0.412\n",
       "27      service        0.679\n",
       "31       member        0.199\n",
       "37        staff        0.634\n",
       "40        theme        0.402\n",
       "49        price        0.240\n",
       "50         wait        0.416\n",
       "62         fast        0.595\n",
       "64        queue        0.676\n",
       "67          bus        0.336\n",
       "72       parade        0.485\n",
       "76       mickey        0.465\n",
       "77        crowd        0.441\n",
       "80       people        0.341\n",
       "88       burger        0.194\n",
       "89       castle        0.389\n",
       "90      coaster        0.238\n",
       "93         time        0.528\n",
       "97         shop        0.241\n",
       "105         eat        0.327\n",
       "114        food        0.478\n",
       "115       drink        0.326\n",
       "124        room        0.353\n",
       "125  attraction        0.567\n",
       "127      ticket        0.297\n",
       "133        push        0.175\n",
       "134  restaurant        0.432\n",
       "150      minute        0.379\n",
       "160        show        0.747\n",
       "162         bar        0.175\n",
       "167      pirate        0.218"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disney_title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01abd3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'disney_title_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# Store variables for further analysis\n",
    "%store disney_title_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
